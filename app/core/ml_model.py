import torch
from transformers import BertTokenizer, BertForSequenceClassification
import os
import logging

# Configurar logging para el modelo
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Ajusta la ruta de tu modelo exportado
MODEL_PATH = os.path.join(os.path.dirname(__file__), "MODELO_ML")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"ğŸ¤– Cargando modelo ML desde: {MODEL_PATH}")
print(f"ğŸ–¥ï¸  Dispositivo de ejecuciÃ³n: {device}")

tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
model = BertForSequenceClassification.from_pretrained(MODEL_PATH).to(device)
model.eval()

print("âœ… Modelo ML cargado exitosamente")

def classify_query(query):
    # Preparar entrada
    inputs = tokenizer(query, return_tensors="pt", padding=True, truncation=True, max_length=128)
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Realizar predicciÃ³n
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        label = torch.argmax(probs, dim=1).item()
        confidence = torch.max(probs, dim=1)[0].item()
        
    # Determinar resultado
    resultado = "Posible SQLi" if label == 1 else "Consulta segura"
    
    # Mostrar reporte en consola
    print("\n" + "="*80)
    print("ğŸ§  REPORTE DE PREDICCIÃ“N DEL MODELO ML")
    print("="*80)
    print(f"ğŸ“ Consulta analizada: {query[:100]}{'...' if len(query) > 100 else ''}")
    print(f"ğŸ” PredicciÃ³n: {resultado}")
    print(f"ğŸ“Š Confianza: {confidence:.4f} ({confidence*100:.2f}%)")
    print(f"ğŸ·ï¸  Etiqueta numÃ©rica: {label} (0=Segura, 1=Vulnerable)")
    print(f"ğŸ“ˆ Probabilidades: Segura={probs[0][0]:.4f}, Vulnerable={probs[0][1]:.4f}")
    print(f"ğŸ–¥ï¸  Dispositivo: {device}")
    print("="*80)
    
    # Log adicional
    logger.info(f"PredicciÃ³n: {resultado} | Confianza: {confidence:.4f} | Query: {query[:50]}...")
    
    return resultado

def analyze_code(parsed_data):
    safe = []
    vulnerable = []
    total_queries = 0
    
    print("\n" + "ğŸš€" + "="*78 + "ğŸš€")
    print("ğŸ”¬ INICIANDO ANÃLISIS COMPLETO DEL CÃ“DIGO")
    print("ğŸš€" + "="*78 + "ğŸš€")
    
    for archivo in parsed_data:
        archivo_nombre = archivo.get('file', 'archivo_desconocido')
        queries = archivo.get("queries", [])
        total_queries += len(queries)
        
        if queries:
            print(f"\nğŸ“ Analizando archivo: {archivo_nombre}")
            print(f"   ğŸ“Š Consultas encontradas: {len(queries)}")
        
        for i, consulta in enumerate(queries, 1):
            # Usar la firma completa si existe, si no usar el SQL
            signature = consulta.get("signature") or consulta.get("sql", "")
            
            print(f"\n   ğŸ” Consulta {i}/{len(queries)}:")
            resultado = classify_query(signature)
            
            if resultado == "Consulta segura":
                safe.append(consulta)
            else:
                vulnerable.append(consulta)
    
    # Resumen final
    print("\n" + "ğŸ“Š" + "="*78 + "ğŸ“Š")
    print("ğŸ“ˆ RESUMEN DEL ANÃLISIS COMPLETO")
    print("ğŸ“Š" + "="*78 + "ğŸ“Š")
    print(f"ğŸ”¢ Total de consultas analizadas: {total_queries}")
    print(f"âœ… Consultas seguras: {len(safe)} ({len(safe)/total_queries*100:.1f}%)")
    print(f"âš ï¸  Consultas vulnerables: {len(vulnerable)} ({len(vulnerable)/total_queries*100:.1f}%)")
    print(f"ğŸ“ Archivos procesados: {len(parsed_data)}")
    
    if vulnerable:
        print(f"\nğŸš¨ VULNERABILIDADES DETECTADAS:")
        for i, vuln in enumerate(vulnerable, 1):
            query = vuln.get('signature') or vuln.get('sql', '')
            print(f"   {i}. {query[:80]}{'...' if len(query) > 80 else ''}")
    
    print("ğŸ“Š" + "="*78 + "ğŸ“Š\n")
    
    return {"safe": safe, "vulnerable": vulnerable}


